{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'B-neutral': 2, 'I-neutral': 3, 'O': 4, 'B-positive': 5, 'I-positive': 6, 'B-negative': 7, 'I-negative': 8, 'stop0': 9, 'stop1': 10, 'start0': 0, 'start1': 1})\n",
      "============================ CN ============================\n",
      "0  out of  546  tweets have been predicted.\n",
      "100  out of  546  tweets have been predicted.\n",
      "200  out of  546  tweets have been predicted.\n",
      "300  out of  546  tweets have been predicted.\n",
      "400  out of  546  tweets have been predicted.\n",
      "500  out of  546  tweets have been predicted.\n",
      "defaultdict(<class 'int'>, {'O': 2, 'B-INTJ': 3, 'B-PP': 4, 'B-NP': 5, 'I-NP': 6, 'B-VP': 7, 'B-PRT': 8, 'I-VP': 9, 'B-ADJP': 10, 'B-SBAR': 11, 'B-ADVP': 12, 'I-INTJ': 13, 'B-CONJP': 14, 'I-CONJP': 15, 'I-ADVP': 16, 'I-ADJP': 17, 'I-SBAR': 18, 'I-PP': 19, 'stop0': 20, 'stop1': 21, 'start0': 0, 'start1': 1})\n",
      "============================ EN ============================\n",
      "0  out of  78  tweets have been predicted.\n",
      "defaultdict(<class 'int'>, {'O': 2, 'B-positive': 3, 'I-positive': 4, 'B-negative': 5, 'B-neutral': 6, 'I-negative': 7, 'I-neutral': 8, 'stop0': 9, 'stop1': 10, 'start0': 0, 'start1': 1})\n",
      "============================ FR ============================\n",
      "0  out of  232  tweets have been predicted.\n",
      "100  out of  232  tweets have been predicted.\n",
      "200  out of  232  tweets have been predicted.\n",
      "defaultdict(<class 'int'>, {'O': 2, 'B-positive': 3, 'I-positive': 4, 'B-negative': 5, 'I-negative': 6, 'B-neutral': 7, 'I-neutral': 8, 'stop0': 9, 'stop1': 10, 'start0': 0, 'start1': 1})\n",
      "============================ SG ============================\n",
      "0  out of  2698  tweets have been predicted.\n",
      "100  out of  2698  tweets have been predicted.\n",
      "200  out of  2698  tweets have been predicted.\n",
      "300  out of  2698  tweets have been predicted.\n",
      "400  out of  2698  tweets have been predicted.\n",
      "500  out of  2698  tweets have been predicted.\n",
      "600  out of  2698  tweets have been predicted.\n",
      "700  out of  2698  tweets have been predicted.\n",
      "800  out of  2698  tweets have been predicted.\n",
      "900  out of  2698  tweets have been predicted.\n",
      "1000  out of  2698  tweets have been predicted.\n",
      "1100  out of  2698  tweets have been predicted.\n",
      "1200  out of  2698  tweets have been predicted.\n",
      "1300  out of  2698  tweets have been predicted.\n",
      "1400  out of  2698  tweets have been predicted.\n",
      "1500  out of  2698  tweets have been predicted.\n",
      "1600  out of  2698  tweets have been predicted.\n",
      "1700  out of  2698  tweets have been predicted.\n",
      "1800  out of  2698  tweets have been predicted.\n",
      "1900  out of  2698  tweets have been predicted.\n",
      "2000  out of  2698  tweets have been predicted.\n",
      "2100  out of  2698  tweets have been predicted.\n",
      "2200  out of  2698  tweets have been predicted.\n",
      "2300  out of  2698  tweets have been predicted.\n",
      "2400  out of  2698  tweets have been predicted.\n",
      "2500  out of  2698  tweets have been predicted.\n",
      "2600  out of  2698  tweets have been predicted.\n",
      "============================ Predictions Complete ============================\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from part4_fun import *\n",
    "    \n",
    "    \n",
    "\n",
    "# main code block\n",
    "if __name__ == '__main__':\n",
    "    outfile = '/dev.p4.out'\n",
    "    \n",
    "    # initializing dictionary where values are the nested list of optimal sentiments\n",
    "    opt_sent_dict = {'EN':[], 'CN':[], 'FR':[], 'SG:':[]} \n",
    "    \n",
    "    \n",
    "    # loop over languages\n",
    "    for lang in languages:\n",
    "        \n",
    "        # ======================================== training ========================================\n",
    "        # reading tweets for particular language\n",
    "        ptrain = data_from_file(lang + '/train') # unmodified\n",
    "        train = mod_train2 (ptrain) # modified w/ start and stop states\n",
    "\n",
    "        # getting sentiments/sentiment pairs and associated indices (w/ start and stop)\n",
    "        sents = get_tags2(ptrain) \n",
    "        sent_pairs = get_tags2pairs(sents)\n",
    "\n",
    "        YY = get_counts2(train, sent_pairs) # dictionary of sentiment pairs and their counts\n",
    "        diff_words = get_words(train)[0] # array of unique words \n",
    "        word_dict = get_words(train)[1] # dictionary of unique words and indices\n",
    "\n",
    "        # emission and transmission parameter matrices\n",
    "        emission_dict = get_emission(train) # dictionary with keys as (x, y) and values as emission probabilities\n",
    "        em_mat = em_matrix(emission_dict, diff_words, sents) # emission matrix\n",
    "        trans_mat2 = transition_params2(train, YY, sents, sent_pairs) # transition matrix\n",
    "        # ========================================================================================== \n",
    "        \n",
    "        # A list of list of tuples of size 1. Each list in test is a tweet. \n",
    "        ptest = data_from_file(lang + '/dev.in')\n",
    "        # test is a list of list. Each sublist is an array of words, 1 tweet\n",
    "        ptest = [[word[0] for word in line] for line in ptest]\n",
    "        test = mod_test2(ptest) # modified with start and stop words\n",
    "        \n",
    "        # initializing list of optimal sentiment lists corresponding to each tweet \n",
    "        optimal_sentiments = []\n",
    "        \n",
    "        print ('============================',lang , '============================')\n",
    "        # loop that runs over all tweets for a given language to predict optimal sentiments\n",
    "        for tweet in range(len(test)):\n",
    "            \n",
    "            base_scores = np.ones([len(sents.keys()),1]) # initializing base case scores\n",
    "            opt_ind_list = viterbi_algo2 (em_mat, trans_mat2, word_dict, test[tweet], base_scores, base_scores, 2, []) # running Viterbi\n",
    "            \n",
    "            # generating list of optimal sentiments for a given sentence\n",
    "            inv_sents = dict (zip(sents.values(), sents.keys())) # swapping keys and values\n",
    "            opt_sents = [inv_sents[opt_ind_list[i]] for i in range(len(opt_ind_list))]\n",
    "\n",
    "            optimal_sentiments.append(opt_sents) # populating parent optimal sentiment list\n",
    "            \n",
    "            # printing iteration checks\n",
    "            if (tweet % 100 == 0):\n",
    "                print (tweet, ' out of ', len(test), ' tweets have been predicted.')\n",
    "        \n",
    "        opt_sent_dict[lang] = optimal_sentiments # populating optimal sentiment dictionary \n",
    "        \n",
    "        predictions = []\n",
    "        for tweet in range(len(optimal_sentiments)):\n",
    "            predictions.append([(ptest[tweet][i], optimal_sentiments[tweet][i]) for i in range(len(optimal_sentiments[tweet]))])\n",
    "        \n",
    "        write_predictions(predictions, lang, outfile)\n",
    "        \n",
    "    \n",
    "    print ('============================ Predictions Complete ============================')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
